% !TeX root = ../main.tex

\section{File manipulation tools}
Analyzing a dataset is useful to get a first impression about it, decide which tools are the most suitable and understand the required hardware.

Files can have a huge variety of formats, when in doubt the \texttt{file} command can be useful.

\textbf{CSV} are \textit{plain text} files containing rows of data separated by a comma, in a simple format with customizable separator. It requires quoting of separators within strings.

\textbf{XML} is a text format encoding of \textit{semi-structured data}, better standardized than CSV but not human writable. It is suitable for nested objects and allows advanced features, yet it is very verbose and its use is declining.

\textbf{JSON} is similar to XML although much simpler and less verbose, easy to write. Its popularity is growing. 

\subsection{Command line tools}
Text formats are overall well-known and can be manipulated with \textbf{command line tools}, a very powerful instrument to perform preliminary analysis:
\begin{itemize}
	\item \texttt{cat} shows the \textit{content} of one or multiple files (works with piped input as well);
	\item \texttt{zcat} is \texttt{cat} for compressed files;
	\item \texttt{less} allows \textit{paging} (chopping long lines);
	\item \texttt{grep} is useful to \textit{search} text through regular expressions, with options such as file formats, lines not matching and case insensitiveness;
	\item \texttt{sort} to (merge) \textit{sort} even large output;
	\item \texttt{uniq} handles \textit{duplicates};
	\item \texttt{tail} and \texttt{less} display \textit{suffixes} and \textit{prefixes};
	\item \texttt{sed} to \textit{edit} text, match and replace characters (in-place update using the same file);
	\item \texttt{join} to \textit{combine} sorted files according to a common field;
	\item \texttt{awk} (followed by a \texttt{BEGIN-END} block) executes a \textit{program} for every line of input, such as average or sum;
	\item \dots
\end{itemize}

Tools can be combined through pipes, which redirect the input/output stream. Some examples are:
\begin{itemize}
	\item \texttt{|} to concatenate two commands (\texttt{\&} also pipes standard error);
	\item \texttt{>} to redirect to a file;
	\item \texttt{<} to redirect from a file;
	\item \texttt{\&\&} executes a command only if the previous one has \textit{succeeded};
	\item \texttt{||} executes a command only if the previous one has \textit{failed};
	\item \texttt{;} separates multiple commands regardless of their output.
\end{itemize}

Process substitution \texttt{<()} allows the input or the output of a command to appear as a file, to avoid verbose commands and extra processing. \\
Example: \texttt{diff <(sort file1) <(sort file2)}

\subsubsection{\texttt{cat}}
Syntax: \texttt{cat [OPTION] [FILE]}

\texttt{cat} concatenates file to standard output. When the file is unspecified, it prints to terminal. It can also be used with multiple files, and different formats (binary, compressed). It is mainly used as input for other commands, since displaying large data can be \textbf{computationally expensive}.

\subsubsection{\texttt{less}}
Syntax: \texttt{less [OPTIONS]}

\texttt{less} is opposite to the analog command \texttt{more}, extending it with other features. \textit{It does not have to read the entire input file before starting}, so with large files it starts up faster than text editors or \texttt{cat}. 

Commands may be preceded by decimal numbers indicating the number of rows to display/scroll, and basic pattern matching can be performed as well. 

\subsubsection{grep}
Syntax: \texttt{grep [OPTION] PATTERNS [FILE]}

It can search (Boyer-Moore algorithm) for any type of string, or any file, or even lists of files and output of commands. It uses basic regular expressions and normal strings.

There also are the variations \texttt{egrep} (for extended regular expressions), \texttt{fgrep} (fixed, to only search strings) and \texttt{rgrep} (recursive, for folders).

Regular expressions syntax:
\begin{itemize}
	\item \texttt{[]} enclose lists of characters (and);
	\item \texttt{-} represents characters range;
	\item \texttt{\^} negates an expression;
	\item \texttt{*} denotes zero or more occurrences of previous character;
	\item \texttt{()} start and end of alternation expression;
	\item \texttt{{n}} range specifier (number of repetitions) $\rightarrow$ \texttt{a\{3\}};
	\item \texttt{\textbackslash<} and \texttt{\textbackslash>} match empty strings at the beginning and the end of a word.
\end{itemize}

\textbf{Extended regular expressions} treat meta-characters without needing to escape them, and are more powerful thanks to the additional commands:
\begin{itemize}
	\item \texttt{?} matches at most one repetition;
	\item \texttt{+} denotes one or more occurrences of previous character;
	\item \texttt{|} matches either of the expressions $\rightarrow$ \texttt{(a|b)}.
\end{itemize}

\texttt{grep} returns all the lines with a match of the pattern. To only return the match, \texttt{-o} option needs to be specified.

\subsubsection{\texttt{sort}}
Syntax: \texttt{sort [OPTION] [FILE]}

\texttt{sort} sorts lines of text files, writing them to standard input. When no file is specified, it reads standard input. Some ordering options are \texttt{-n} (numeric), \texttt{-r} (reverse), \texttt{-k} (specific key), \texttt{-u} (removes duplicates).

It can handle files larger than main memory, and it is very useful to prepare input for other algorithms.

\subsubsection{\texttt{head} / \texttt{tail}}
Syntax: \texttt{HEAD [OPTION] [FILE]}

Those commands print the first (last) lines of files. The default number of lines is 10, and multiple files can be read. 

An integer can be specified as option to determine how many lines must be read (and skipped). Those commands are relevant to extract \textbf{minimum} and \textbf{maximum} of computations. Numbers may have a multiplier suffix, indicating bytes or related measurement units.

\subsubsection{\texttt{uniq}}
Syntax: \texttt{uniq [OPTION] [INPUT [OUTPUT]]}

\texttt{uniq} handles (adjancent) duplicates (similarly to SQL \texttt{DISTINCT}) in sorted input, reporting or omitting them. It also has option \texttt{-c} to count duplicates or \texttt{-u} for unique lines. With no options, matching lines are merged to the first occurrence.

Its main applications are grouping and counting input.

\subsubsection{\texttt{cut}}
Syntax: \texttt{cut [OPTION] [FILE]}

\texttt{cut} removes section from each line of files. This can be seen as selecting columns from a CSV, where relevant parts of delimited input get redirected to output.

Example: \texttt{cat file | cut -f 1, 3} \\
Returns specific fields of file, delimiter can be specified with \texttt{-d}.

\subsubsection{\texttt{wc}}
Syntax: \texttt{wc [OPTION] [FILE]}

\texttt{wc} prints newline, word and byte counts for each file (and a total line if more than one file is specified). A word is a non-zero-length sequence of characters delimited by white space.

Options may be used to select which counts are printed: \texttt{-c} for bytes, \texttt{-m} for chars, \texttt{-l} for lines and so on.

\subsubsection{\texttt{shuf}}
Syntax: \texttt{shuf [OPTION] [FILE]}

This command generates random permutations of the input lines to standard output. It is not so common, although very useful when extracting random samples and running \textbf{performance tests}.

\subsubsection{\texttt{sed}}
Syntax: \texttt{sed [OPTION] {script} [FILE]}

\texttt{sed} is a \textit{stream editor} to perform basic text transformations on an input stream (or file). It works by making only one pass over the input, therefore it is more efficient than scripts. It can also filter text in a pipeline.

This command is mostly used to replace text in a file. The operations are separated by a slash, and the letters (flags) represent options.

Example: \texttt{cat file | sed 's/oldText/newText/'} \\
Replaces \textit{oldText} with \textit{newText}.

Example: \texttt{cat file | sed 's/file[0-9]*.png/"\&"/I'} \\
Case insensitive matching and replacing.

\subsubsection{\texttt{join}}
Syntax: \texttt{join [OPTION] FILE1 FILE2}

\texttt{join} joins the lines of two files on a common field. For each pair of input lines with identical join fields, writes a line to standard output. The default join field is the first, delimited by blanks. One file can be omitted, reading standard output.

Unmatched lines are removed, or preserved with \texttt{-a}.

Field number can be specified with \texttt{-j} or \texttt{-1 FIELD -2 FIELD}. Values must be sorted before joining, and it is not powerful compared to other tools.

\subsubsection{\texttt{awk}}
Syntax: \texttt{gawk [POSIX or GNU style options] -f program-file [--] file}

Gawk is the GNU project's implementation of the AWK programming language, according to the POSIX standards. The command line takes as input the AWK program text.

Gawk also has an integrated debugger and profiling statistics for the execution of programs.

AWK's general structure is: \\
\texttt{awk 'BEGIN {init-code} {per-line-code} END {done-code}' file}

Example: \texttt{awk 'BEGIN {x=0; y=0} {x=x+\$2; y=y+1} END {print x/y}'} \\
Computes the average of column 2 (identified with the dollar).
