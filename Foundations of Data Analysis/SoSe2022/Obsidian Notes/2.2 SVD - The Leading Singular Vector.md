## 2.2 The Leading Singular Vector
%% #Lecture 3, 09.05. %%

> For $A \in \mathbb K^{m\times n}$, the **singular vectors** are the maximizers 
> $$v_1 = \arg\max_{||v||_2 = 1} ||Av||_2$$
> $$v_k = \arg\max_{\substack{||v||_2=1, \\v\bot v_1,\dots,v_{k-1}}}||Av||_2$$


Some geometric intuition: *the space $V_k$ spanned by the first $k$ singular vectors is the $k$-dim. subspace closest to the ~~columns~~ rows of $A$, in the $\ell_2$ sense.* Formally: $V_k = \arg\min_{V~\text{k-dim subspace}} \sum_j dist(A^{(j)}, V)^2$. In a sense, this is a least-squares regression!

Recall: by Pythagoras, $\sum_j x_{ij}^2 = ||P_V x_i||^2 + ||dist(x_i, V)||^2$.

![[pythagoras.png|400]]

 ###### *#Proof: SVD <=> closest subspace* (in the simpler $k=1$ case)
Let $V_1$ be the min. subspace (geometric def.). I.e. $V$ minimizes $\sum_{i,j} x_{ij}^2 - ||P_V x_i||_2^2$, and hence also maximizes $||P_V x_i||_2^2$. We assume $\dim V=1$ for now, so $V = span(v)$ for some $v$, $||v||=1$. For any $z$, $P_V z = \langle z, v \rangle v$.  So $||P_V x_i||_2^2 = |\langle x_i, v \rangle|^2 ||v||_2^2 = |\langle x_i, v\rangle |^2$ . As $x_i = A^{(i)}$, $\sum_i |\langle A^{(i)}, v\rangle |^2 = ||Av||_2^2$.

Summary: *the leading singular vector $v_1$ spans the line fitting the data points given by the columns of $A$ in least-squares sense*.

### Computing the leading SV
Consider the reals for now. Goal: max. $||Av||_2$ over the unit circle. Equiv. max $||Av||_2^2$ subj. to $||v||_2^2 = 1$ (to make the objective + constraint smooth).

==Lagrange multipliers==: #TODO  Look this up.
Motivation: for a smooth function, a local minimum (without constraints) always implies "gradient = 0". Lagrange multipliers instead also bring in the gradient of the constraint: for some $\lambda$,
$$\nabla f(v) + \lambda \nabla g(v) = 0$$
###### *#Proof: Solving min. problem for computing leading SV*
$f(v) = ||Av||_2^2 = v^H A^HA v = \langle v, A^H A v \rangle$ and $g(v) = ||v||_2^2 - 1  = \langle v, v \rangle - 1$. Hence $\nabla f(v) = 2 A^H A v$ and $\nabla g(v) = 2v$. Lagrange multiplier eq: $2A^H A v + \lambda 2v = 0$. #TODO Apparently this is the eigenvector equation: Find the eigenvalues of $A^H A$, find associated eigenvectors (linear system solving), find the one that maximizes $||Av||_2^2$.

